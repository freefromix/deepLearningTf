{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import  pickle as pkl\n",
    "import  networkx as nx\n",
    "import  scipy.sparse as sp\n",
    "from    scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import  sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_index_file(filename):\n",
    "    \"\"\"\n",
    "    Parse index file.\n",
    "    \"\"\"\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"\n",
    "    Create mask.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "- [PubMed Diabetes](https://linqs.soe.ucsc.edu/data): The Pubmed Diabetes dataset consists of 19717 scientific publications from PubMed database pertaining to diabetes classified into one of three classes. The citation network consists of 44338 links. Each publication in the dataset is described by a TF/IDF weighted word vector from a dictionary which consists of 500 unique words. The README file in the dataset provides more details.\n",
    "\n",
    "- [Cora](https://linqs.soe.ucsc.edu/data) : The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words. The README file in the dataset provides more details. \n",
    "\n",
    "- [CiteSeer](https://linqs-data.soe.ucsc.edu/public/citeseer-mrdm05/) for Entity Resolution: The CiteSeer dataset contains 1504 machine learning documents with 2892 author references to 165 author entities. For this dataset, the only attribute information available is author name. The full last name is always given, and in some cases the authorâ€™s full first name and middle name are given and other times only the initials are given.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_str):\n",
    "    \"\"\"\n",
    "    Loads input data from gcn/data directory\n",
    "\n",
    "    ind.dataset_str.x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training instances\n",
    "        (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n",
    "    ind.dataset_str.ty => the one-hot labels of the test instances as numpy.ndarray object;\n",
    "    ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
    "    ind.dataset_str.graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict\n",
    "        object;\n",
    "    ind.dataset_str.test.index => the indices of test instances in graph, for the inductive setting as list object.\n",
    "\n",
    "    All objects above must be saved using python pickle module.\n",
    "\n",
    "    :param dataset_str: Dataset name\n",
    "    :return: All data input files loaded (as well the training/test data).\n",
    "    \"\"\"\n",
    "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        print(\"data/ind.{}.{}\".format(dataset_str, names[i]))\n",
    "        with open(\"data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset_str))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "    print('type(x)', type(x), 'x.shape', x.shape)\n",
    "    print('type(y)', type(y), 'y.shape', y.shape)\n",
    "    print('x[0]', type(x[139]))\n",
    "    print('x[0]', x[139].shape)\n",
    "    print('x[0]', x[139])\n",
    "\n",
    "    if dataset_str == 'citeseer':\n",
    "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
    "        # Find isolated nodes, add them as zero-vecs into the right position\n",
    "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
    "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
    "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
    "        tx = tx_extended\n",
    "        ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
    "        ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
    "        ty = ty_extended\n",
    "\n",
    "    features = sp.vstack((allx, tx)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "\n",
    "    labels = np.vstack((ally, ty))\n",
    "    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "    idx_test = test_idx_range.tolist()\n",
    "    idx_train = range(len(y))\n",
    "    idx_val = range(len(y), len(y)+500)\n",
    "\n",
    "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "    y_train = np.zeros(labels.shape)\n",
    "    y_val = np.zeros(labels.shape)\n",
    "    y_test = np.zeros(labels.shape)\n",
    "    y_train[train_mask, :] = labels[train_mask, :]\n",
    "    y_val[val_mask, :] = labels[val_mask, :]\n",
    "    y_test[test_mask, :] = labels[test_mask, :]\n",
    "\n",
    "    return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ind.cora.x\n",
      "data/ind.cora.y\n",
      "data/ind.cora.tx\n",
      "data/ind.cora.ty\n",
      "data/ind.cora.allx\n",
      "data/ind.cora.ally\n",
      "data/ind.cora.graph\n",
      "type(x) <class 'scipy.sparse.csr.csr_matrix'> x.shape (140, 1433)\n",
      "type(y) <class 'numpy.ndarray'> y.shape (140, 7)\n",
      "x[0] <class 'scipy.sparse.csr.csr_matrix'>\n",
      "x[0] (1, 1433)\n",
      "x[0]   (0, 1)\t1.0\n",
      "  (0, 41)\t1.0\n",
      "  (0, 187)\t1.0\n",
      "  (0, 212)\t1.0\n",
      "  (0, 357)\t1.0\n",
      "  (0, 404)\t1.0\n",
      "  (0, 464)\t1.0\n",
      "  (0, 505)\t1.0\n",
      "  (0, 507)\t1.0\n",
      "  (0, 581)\t1.0\n",
      "  (0, 635)\t1.0\n",
      "  (0, 874)\t1.0\n",
      "  (0, 988)\t1.0\n",
      "  (0, 1071)\t1.0\n",
      "  (0, 1230)\t1.0\n",
      "  (0, 1231)\t1.0\n",
      "  (0, 1258)\t1.0\n",
      "  (0, 1263)\t1.0\n",
      "  (0, 1274)\t1.0\n",
      "  (0, 1393)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(\"cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
